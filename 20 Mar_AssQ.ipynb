{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a6f280-933b-40eb-bc37-e1ae9178320e",
   "metadata": {},
   "source": [
    "Q1. What is data encoding? How is it useful in data science?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a419a4-6608-4aea-a320-2e4225d230ca",
   "metadata": {},
   "source": [
    "## Data Encoding in Data Science\n",
    "\n",
    "### Definition\n",
    "\n",
    "Data encoding is the process of converting data from one format to another. This can involve transforming categorical data into numerical values or converting data to a format suitable for storage or transmission. Encoding is a crucial step in data preprocessing, especially when preparing data for machine learning models.\n",
    "\n",
    "### Types of Data Encoding\n",
    "\n",
    "1. **Label Encoding**: This assigns a unique integer to each category. For example, \"red,\" \"green,\" and \"blue\" could be encoded as 1, 2, and 3 respectively.\n",
    "2. **One-Hot Encoding**: This creates binary columns for each category. For instance, \"red,\" \"green,\" and \"blue\" would be represented as three columns, with a 1 in the corresponding column and 0s elsewhere.\n",
    "3. **Binary Encoding**: This is a mix of label encoding and binary conversion. Categories are first converted to numerical values, then to binary format.\n",
    "4. **Frequency Encoding**: This replaces categories with their frequency or count.\n",
    "5. **Target Encoding**: This involves replacing a categorical value with the mean of the target variable for that category.\n",
    "6. **Ordinal Encoding**: This assigns ordered integers to categories, which is useful when the categories have a logical order.\n",
    "\n",
    "### Utility in Data Science\n",
    "\n",
    "1. **Machine Learning Models**: Most machine learning algorithms require numerical input. Encoding transforms categorical data into a numerical format, making it usable by algorithms.\n",
    "2. **Feature Engineering**: Proper encoding can help in creating new features that improve model performance.\n",
    "3. **Data Compression**: Encoding can reduce the storage space needed for data.\n",
    "4. **Standardization**: Encoding ensures consistency in data representation, especially when integrating data from multiple sources.\n",
    "5. **Improved Performance**: Effective encoding can lead to more accurate and faster models by providing better input data.\n",
    "6. **Handling Missing Values**: Some encoding techniques can help in dealing with missing data.\n",
    "\n",
    "\n",
    "Data encoding is a fundamental step in the data preprocessing pipeline in data science. It ensures that data is in the right format for analysis and modeling, improving the performance and accuracy of machine learning algorithms."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ec3691e-5673-4e71-b84e-9976dfd10a2b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85882961-576b-4ef5-ba09-56a0deaf6995",
   "metadata": {},
   "source": [
    "Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb31c9a-b0fe-4101-b13d-16203e1bd1d3",
   "metadata": {},
   "source": [
    "## Nominal Encoding\n",
    "\n",
    "### Definition\n",
    "\n",
    "Nominal encoding is a method of converting categorical data into numerical format without implying any order or hierarchy among the categories. This type of encoding is typically used when dealing with nominal data, which consists of categories that do not have a logical order. The most common methods of nominal encoding are one-hot encoding and label encoding.\n",
    "\n",
    "### Methods of Nominal Encoding\n",
    "\n",
    "1. **One-Hot Encoding**: This method creates binary columns for each category. Each original category is represented by a unique binary vector. This is suitable when there are a limited number of categories, as it can create a large number of columns for high cardinality features.\n",
    "2. **Label Encoding**: This method assigns a unique integer to each category. While it is simple and efficient, it might introduce unintended ordinal relationships between categories.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e62949d-e2ec-4c4d-8c39-2f807925280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Real-World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edac77-312d-4c20-9b45-b8f243a711f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-Hot Encoding Example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'CustomerID': [1, 2, 3, 4, 5],\n",
    "        'Country': ['USA', 'Canada', 'Mexico', 'USA', 'Canada'],\n",
    "        'Age': [25, 30, 35, 40, 45],\n",
    "        'Income': [50000, 60000, 70000, 80000, 90000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Country'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fdb47-c437-4c23-9755-652944484c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding Example\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'CustomerID': [1, 2, 3, 4, 5],\n",
    "        'Country': ['USA', 'Canada', 'Mexico', 'USA', 'Canada'],\n",
    "        'Age': [25, 30, 35, 40, 45],\n",
    "        'Income': [50000, 60000, 70000, 80000, 90000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "df['Country_Encoded'] = le.fit_transform(df['Country'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1080182-84cc-47ae-b321-c531af845488",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Nominal encoding is essential in data preprocessing, especially when dealing with categorical variables that do not have an inherent order. By converting these categories into numerical formats, nominal encoding facilitates the use of such data in machine learning models and other analytical processes. The choice between one-hot encoding and label encoding depends on the specific requirements of the model and the nature of the categorical data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e710b22c-02c4-4cbe-a887-abdb8fa9a584",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de83ac63-d4ae-496a-8182-42b48a021d10",
   "metadata": {},
   "source": [
    "Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8689796a-076e-43ac-9cb7-cf7f12b416ba",
   "metadata": {},
   "source": [
    "Nominal encoding (e.g., label encoding) can be preferred over one-hot encoding in certain situations, especially when dealing with high-cardinality categorical features or when the specific machine learning algorithm can handle the encoded values appropriately. Here are some situations where nominal encoding is preferred:\n",
    "\n",
    "### Situations Where Nominal Encoding is Preferred\n",
    "\n",
    "1. **High Cardinality Features**:\n",
    "   - When a categorical feature has a large number of unique values, one-hot encoding can lead to a very high-dimensional dataset, which can be computationally expensive and may cause issues like overfitting. Nominal encoding keeps the dimensionality low.\n",
    "   \n",
    "2. **Tree-Based Algorithms**:\n",
    "   - Tree-based algorithms like Decision Trees, Random Forests, and Gradient Boosting Machines can handle label encoded data effectively because they split nodes based on the values of the features and do not assume any order in the values.\n",
    "\n",
    "3. **Memory and Computational Efficiency**:\n",
    "   - When memory and computational resources are limited, nominal encoding is more efficient because it reduces the number of columns, leading to lower memory usage and faster computations.\n",
    "\n",
    "4. **Ordinal Relationships**:\n",
    "   - Although nominal encoding does not assume an ordinal relationship, if there is a logical order to the categories and you want to introduce some ordinal encoding without implying strict ranking, label encoding can be a simple solution.\n",
    "\n",
    "**Reasons for Choosing Nominal Encoding**:\n",
    "\n",
    "\n",
    "1. **High Cardinality**: With a large number of unique genres, one-hot encoding would result in a very high-dimensional dataset. If there are 50 unique genres, one-hot encoding would create 50 new columns.\n",
    "2. **Tree-Based Model**: If you plan to use a tree-based algorithm like Random Forest, the model can handle label encoded values effectively without assuming any ordinal relationship.\n",
    "3. **Efficiency**: Label encoding keeps the feature as a single column, which is more efficient in terms of memory and computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5def6a-465e-4b08-9112-d984d88860fb",
   "metadata": {},
   "source": [
    "### Practical Example\n",
    "\n",
    "#### Scenario: Predicting User Preferences in a Music Streaming Service\n",
    "**Implementing Nominal Encoding (Label Encoding)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fe096-f71a-4024-a7ee-c9d04076acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'UserID': [1, 2, 3, 4, 5],\n",
    "    'Age': [25, 30, 22, 35, 28],\n",
    "    'FavoriteGenre': ['Rock', 'Pop', 'Jazz', 'Classical', 'Hip-Hop']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "df['FavoriteGenre_Encoded'] = le.fit_transform(df['FavoriteGenre'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e2e1f-b690-4d65-bc60-3e320ab2c76f",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Nominal encoding is preferred over one-hot encoding when dealing with high-cardinality features, tree-based algorithms, or when memory and computational efficiency are critical concerns. In the example of predicting user preferences in a music streaming service, nominal encoding is more efficient and suitable due to the large number of unique genres and the intended use of tree-based algorithms."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dfa086f-9b2d-4dd5-bf82-4ef060cdfacf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93ac1610-1075-45f0-9905-eaaacb81079a",
   "metadata": {},
   "source": [
    "Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding technique would you use to transform this data into a format suitable for machine learning algorithms? \n",
    "Explain why you made this choice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9e9c0-1f46-4fc8-9538-f0a36133b45e",
   "metadata": {},
   "source": [
    "### Choosing the Right Encoding Technique\n",
    "\n",
    "Given a dataset with a categorical feature containing 5 unique values, the choice of encoding technique depends on several factors, including the nature of the categorical data and the machine learning algorithm being used. \n",
    "\n",
    "### Recommended Encoding Technique: One-Hot Encoding\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Non-ordinal Nature**: If the categorical values do not have a natural order (e.g., colors, types of animals, etc.), one-hot encoding is generally the best choice. One-hot encoding ensures that no unintended ordinal relationship is introduced between the categories, which could negatively impact the performance of some machine learning algorithms.\n",
    "  \n",
    "2. **Interpretability**: One-hot encoded variables are easy to interpret. Each column represents a specific category, making it straightforward to understand the presence or absence of each category in the data.\n",
    "\n",
    "3. **Algorithm Compatibility**: Many machine learning algorithms, especially linear models (e.g., linear regression, logistic regression) and tree-based models (e.g., decision trees, random forests, gradient boosting), work well with one-hot encoded data. These algorithms can exploit the binary nature of the encoded features without assuming any ordinal relationship.\n",
    "\n",
    "4. **Low Cardinality**: With only 5 unique values, one-hot encoding will produce 5 new binary columns, which is manageable in terms of computational efficiency and storage. This small number of columns ensures that the model remains efficient and not overly complex.\n",
    "\n",
    "\n",
    "### Alternative: Label Encoding\n",
    "\n",
    "**When to Use**:\n",
    "- **Ordinal Nature**: If the categorical data has a natural order (e.g., low, medium, high), label encoding may be appropriate.\n",
    "- **Certain Algorithms**: Some algorithms like tree-based models can handle label encoded data effectively, even if the data is non-ordinal.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d376e9e-71ae-4665-85e7-8b287aead008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### One-Hot Encoding Example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Fruit': ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Fruit'])\n",
    "\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c64f8-ebb8-4b85-8aef-7ccbdf1a8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Label Encoding Example\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "df['Fruit_Encoded'] = le.fit_transform(df['Fruit'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee646f2b-43df-4811-9d9d-19a83255b6c5",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "For a dataset with 5 unique categorical values and no inherent order, one-hot encoding is generally the best choice. It avoids introducing any artificial ordinal relationships, ensures interpretability, and works well with a wide range of machine learning algorithms. However, the specific context and nature of the categorical data should always be considered when choosing the encoding technique."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9251452b-84ff-4154-9ac0-5499d95ff016",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44aefe33-9fc8-4497-81fb-8d51283e291a",
   "metadata": {},
   "source": [
    "Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns \n",
    "are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to \n",
    "transform the categorical data, how many new columns would be created? Show your calculations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7fde5-e636-4699-b01f-bbf1b9688ee2",
   "metadata": {},
   "source": [
    "To determine how many new columns would be created using nominal encoding (one-hot encoding) for the two categorical columns, we need to follow these steps:\n",
    "\n",
    "1. **Identify the number of unique values in each categorical column**.\n",
    "2. **Calculate the total number of new columns created by one-hot encoding each categorical column**.\n",
    "\n",
    "### Step-by-Step Calculation\n",
    "\n",
    "1. **Count the number of unique values in each categorical column**:\n",
    "   - Assume the first categorical column has \\( n1 \\) unique values.\n",
    "   - Assume the second categorical column has \\( n2 \\) unique values.\n",
    "\n",
    "2. **One-Hot Encoding**:\n",
    "   - For each unique value in a categorical column, one-hot encoding creates a new binary column.\n",
    "   - Therefore, the first categorical column will create \\( n1 \\) new columns.\n",
    "   - The second categorical column will create \\( n2 \\) new columns.\n",
    "\n",
    "3. **Total New Columns**:\n",
    "   - The total number of new columns created by one-hot encoding both categorical columns is the sum of the unique values in both columns, i.e., \\( n1 + n2 \\).\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Let's assume:\n",
    "- The first categorical column has 4 unique values.\n",
    "- The second categorical column has 3 unique values.\n",
    "\n",
    "Using one-hot encoding:\n",
    "\n",
    "- The first categorical column will create \\( 4 \\) new columns.\n",
    "- The second categorical column will create \\( 3 \\) new columns.\n",
    "\n",
    "### Total Number of New Columns\n",
    "\\[ \\text{Total New Columns} = n1 + n2 = 4 + 3 = 7 \\]\n",
    "\n",
    "### Final Answer\n",
    "\n",
    "If you were to use one-hot encoding to transform the categorical data in the given dataset:\n",
    "\n",
    "- The total number of new columns created would be **7**.\n",
    "\n",
    "### Final Dataset Structure\n",
    "\n",
    "- Original columns: 5\n",
    "- New columns created by encoding: 7\n",
    "- Total columns after encoding: \\( 5 - 2 + 7 = 10 \\)\n",
    "\n",
    "So, the final dataset will have 10 columns."
   ]
  },
  {
   "cell_type": "raw",
   "id": "07c43065-3578-4182-aa66-99804c9b447f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f32c2ba-5af9-4461-a5bc-296d6d6a616e",
   "metadata": {},
   "source": [
    "Q6. You are working with a dataset containing information about different types of animals, including their \n",
    "species, habitat, and diet. Which encoding technique would you use to transform the categorical data into \n",
    "a format suitable for machine learning algorithms? Justify your answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fc3b8-2fcf-41b9-a2dc-06208d8bb02b",
   "metadata": {},
   "source": [
    "### Choosing the Right Encoding Technique for Animal Dataset\n",
    "\n",
    "Given a dataset containing information about different types of animals, including their species, habitat, and diet, the appropriate encoding technique should be chosen based on the nature of the categorical data and the requirements of the machine learning algorithms. Here’s a step-by-step approach to determine the best encoding technique:\n",
    "\n",
    "1. **Identify the Nature of Categorical Data**:\n",
    "   - **Species**: This is likely nominal data, as species do not have a natural order.\n",
    "   - **Habitat**: This is also nominal, as different habitats (e.g., forest, desert, ocean) do not have an inherent order.\n",
    "   - **Diet**: This is nominal too, as diet types (e.g., herbivore, carnivore, omnivore) do not have an inherent order.\n",
    "\n",
    "2. **Choose the Encoding Technique**:\n",
    "   - Since all three categorical features are nominal and do not have a natural order, **One-Hot Encoding** is the most suitable technique.\n",
    "\n",
    "### Justification for One-Hot Encoding\n",
    "\n",
    "1. **Non-Ordinal Nature**: One-hot encoding does not assume any order among categories, making it ideal for nominal data like species, habitat, and diet.\n",
    "2. **Algorithm Compatibility**: Many machine learning algorithms, such as linear models and tree-based models, work well with one-hot encoded data. These algorithms can handle the binary nature of the encoded features without assuming any ordinal relationship.\n",
    "3. **Interpretability**: One-hot encoding provides clear and interpretable binary columns, where each column represents the presence or absence of a particular category. This makes it easier to understand the model’s decisions.\n",
    "4. **Low to Moderate Cardinality**: If the number of unique categories in each column is not excessively high, one-hot encoding is computationally feasible and does not significantly increase the dimensionality of the dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324ce36-ca5b-4e5b-b482-5f7ef3ea33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example of One-Hot Encoding for Animal Dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Animal': ['Lion', 'Elephant', 'Penguin', 'Kangaroo', 'Bear'],\n",
    "    'Species': ['Lion', 'Elephant', 'Penguin', 'Kangaroo', 'Bear'],\n",
    "    'Habitat': ['Savannah', 'Forest', 'Antarctic', 'Grassland', 'Forest'],\n",
    "    'Diet': ['Carnivore', 'Herbivore', 'Carnivore', 'Herbivore', 'Omnivore']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Species', 'Habitat', 'Diet'])\n",
    "\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca81de9-c959-4aa5-998c-5cfdfef9ca01",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "For a dataset containing information about different types of animals with nominal categorical data (species, habitat, diet), one-hot encoding is the most appropriate technique. It avoids introducing any artificial ordinal relationships, ensures interpretability, and works well with a wide range of machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08830e94-9d6d-48fb-9d85-775e21c67f8a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d2c06dd-16a7-4d34-abc2-1830edafa48a",
   "metadata": {},
   "source": [
    "Q7.You are working on a project that involves predicting customer churn for a telecommunications \n",
    "company. You have a dataset with 5 features, including the customer's gender, age, contract type, \n",
    "monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical \n",
    "data into numerical data? Provide a step-by-step explanation of how you would implement the encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145053d-0544-473a-97bb-3f146029e381",
   "metadata": {},
   "source": [
    "### Encoding Categorical Data for Customer Churn Prediction\n",
    "\n",
    "In a project involving predicting customer churn for a telecommunications company, the dataset includes the following features:\n",
    "1. Gender (categorical)\n",
    "2. Age (numerical)\n",
    "3. Contract type (categorical)\n",
    "4. Monthly charges (numerical)\n",
    "5. Tenure (numerical)\n",
    "\n",
    "To transform the categorical data into numerical data suitable for machine learning algorithms, we'll focus on encoding the \"Gender\" and \"Contract type\" features. Here’s a step-by-step approach:\n",
    "\n",
    "### Step-by-Step Explanation\n",
    "\n",
    "#### Step 1: Identify Categorical Features\n",
    "\n",
    "1. **Gender**: Nominal categorical feature with likely two unique values (e.g., Male, Female).\n",
    "2. **Contract Type**: Nominal categorical feature with multiple unique values (e.g., Month-to-month, One year, Two year).\n",
    "\n",
    "#### Step 2: Choose Encoding Techniques\n",
    "\n",
    "1. **Gender**: Since this feature has only two unique values, we can use **Label Encoding** or **Binary Encoding**.\n",
    "2. **Contract Type**: Since this feature has more than two unique values, we use **One-Hot Encoding** to avoid introducing any ordinal relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e0d86-adce-4bec-a6e6-d7d5c4210f56",
   "metadata": {},
   "source": [
    "#### Step 3: Implement the Encoding\n",
    "**Step 3.1: Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a70e366-3bf9-4fb1-931d-2ef67b7b4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'Age': [34, 45, 23, 36, 52],\n",
    "    'Contract': ['Month-to-month', 'One year', 'Two year', 'Month-to-month', 'Two year'],\n",
    "    'MonthlyCharges': [29.85, 56.95, 53.85, 42.30, 70.70],\n",
    "    'Tenure': [1, 34, 2, 45, 8]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c7fb5-694a-4ea9-bee2-c86912879586",
   "metadata": {},
   "source": [
    "**Step 3.2: Encode the \"Gender\" Feature Using Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535e8656-5007-4526-9730-4cdd6e399b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding for Gender\n",
    "le = LabelEncoder()\n",
    "df['Gender_Encoded'] = le.fit_transform(df['Gender'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce98d68-50e4-45f0-8552-0d65369ca364",
   "metadata": {},
   "source": [
    "\n",
    "**Step 3.3: Encode the \"Contract Type\" Feature Using One-Hot Encoding**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75093723-2db8-46ec-8a27-c7b34a5198e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Age  MonthlyCharges  Tenure  Gender_Encoded  \\\n",
      "0    Male   34           29.85       1               1   \n",
      "1  Female   45           56.95      34               0   \n",
      "2  Female   23           53.85       2               0   \n",
      "3    Male   36           42.30      45               1   \n",
      "4  Female   52           70.70       8               0   \n",
      "\n",
      "   Contract_Month-to-month  Contract_One year  Contract_Two year  \n",
      "0                        1                  0                  0  \n",
      "1                        0                  1                  0  \n",
      "2                        0                  0                  1  \n",
      "3                        1                  0                  0  \n",
      "4                        0                  0                  1  \n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for Contract\n",
    "df_encoded = pd.get_dummies(df, columns=['Contract'])\n",
    "\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5119bf6-b665-4f9b-b80b-99b311c53d5f",
   "metadata": {},
   "source": [
    "### Final Dataset Structure\n",
    "\n",
    "The final dataset will have the following columns after encoding:\n",
    "\n",
    "1. Age (numerical)\n",
    "2. MonthlyCharges (numerical)\n",
    "3. Tenure (numerical)\n",
    "4. Gender_Encoded (binary)\n",
    "5. Contract_Month-to-month (binary)\n",
    "6. Contract_One year (binary)\n",
    "7. Contract_Two year (binary)\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "By using **Label Encoding** for the \"Gender\" feature and **One-Hot Encoding** for the \"Contract Type\" feature, we ensure that the categorical data is transformed into a numerical format suitable for machine learning algorithms. This approach maintains interpretability and avoids introducing any unintended ordinal relationships among the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e067bc-2d15-45c2-abcc-a24bedc833ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
